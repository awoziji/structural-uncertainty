{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('../data/concrete.txt')\n",
    "np.random.shuffle(data)\n",
    "cutoff = int(len(data)*0.8)\n",
    "X_train, y_train  = data[:cutoff, :-1], data[:cutoff, -1]\n",
    "X_test, y_test = data[cutoff:, :-1], data[cutoff:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "std_X_train = np.std(X_train, 0)\n",
    "std_X_train[std_X_train == 0] = 1\n",
    "mean_X_train = np.mean(X_train, 0)\n",
    "X_train = (X_train - np.full(X_train.shape, mean_X_train)) / np.full(X_train.shape, std_X_train)\n",
    "X_test = (X_test - np.full(X_test.shape, mean_X_train)) / np.full(X_test.shape, std_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set model params\n",
    "model_params = {\"learning_rate\": 0.001,\n",
    "                \"dropout\": 0.01,\n",
    "                \"hidden_width\": 50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "    '''\n",
    "    features: A dict containing the features passed to the model via input_fn.\n",
    "    labels: A Tensor containing the labels passed to the model via input_fn. \n",
    "            Will be empty for predict() calls, as these are the values the model will infer.\n",
    "    mode: One of the following tf.estimator.ModeKeys string values indicating the context in which \n",
    "          the model_fn was invoked\n",
    "          \n",
    "    Return: tf.estimator.EstimatorSpec object\n",
    "    '''\n",
    "    ### 1. Configure the model via TensorFlow operations\n",
    "    \n",
    "    # Connect the first hidden layer to input layer\n",
    "    # (features[\"x\"]) with relu activation\n",
    "    \n",
    "    dropout_1 = tf.layers.dropout(inputs=features[\"x\"],\n",
    "                            rate=params['dropout'],\n",
    "                            training=True)\n",
    "    \n",
    "    hidden_layer = tf.layers.dense(dropout_1, \n",
    "                                         units=params['hidden_width'],\n",
    "                                         activation=tf.nn.relu)\n",
    "\n",
    "    dropout_2 = tf.layers.dropout(inputs=hidden_layer,\n",
    "                                rate=params['dropout'],\n",
    "                                training=True)\n",
    "\n",
    "    output_layer = tf.layers.dense(dropout_2, \n",
    "                                   units=1)\n",
    "\n",
    "    predictions = tf.reshape(output_layer, [-1])\n",
    "    \n",
    "    # Provide an estimator spec for `ModeKeys.PREDICT`.\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                          predictions={\"y\": predictions})\n",
    "    \n",
    "    #onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10)\n",
    "    #loss = tf.losses.softmax_cross_entropy(onehot_labels=onehot_labels, logits=logits)\n",
    "    \n",
    "    ### 2. Define the loss function for training/evaluation\n",
    "    loss = tf.losses.mean_squared_error(labels, predictions)\n",
    "    eval_metric_ops = {\"rmse\": \n",
    "                       tf.metrics.root_mean_squared_error(tf.cast(labels, tf.float64), predictions)}\n",
    "    \n",
    "    ### 3. Define the training operation/optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=params[\"learning_rate\"])\n",
    "    train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "    \n",
    "    \n",
    "    ### 4. Return predictions/loss/train_op/eval_metric_ops in EstimatorSpec object\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                      loss=loss,\n",
    "                                      train_op=train_op,\n",
    "                                      eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp06v_ijxe\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {}\n"
     ]
    }
   ],
   "source": [
    "# Instantiate Estimator\n",
    "nn = tf.estimator.Estimator(model_fn=model_fn, params=model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_train},\n",
    "    y=y_train,\n",
    "    batch_size=32,\n",
    "    num_epochs=None,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmp06v_ijxe/model.ckpt.\n",
      "INFO:tensorflow:loss = 1573.19, step = 1\n",
      "INFO:tensorflow:global_step/sec: 765.723\n",
      "INFO:tensorflow:loss = 1219.06, step = 101 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 792.037\n",
      "INFO:tensorflow:loss = 1672.99, step = 201 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 804.939\n",
      "INFO:tensorflow:loss = 681.691, step = 301 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 805.644\n",
      "INFO:tensorflow:loss = 439.247, step = 401 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 800.435\n",
      "INFO:tensorflow:loss = 367.938, step = 501 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 761.937\n",
      "INFO:tensorflow:loss = 265.374, step = 601 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 779.858\n",
      "INFO:tensorflow:loss = 229.072, step = 701 (0.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 713.84\n",
      "INFO:tensorflow:loss = 263.757, step = 801 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 743.037\n",
      "INFO:tensorflow:loss = 293.756, step = 901 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 756.382\n",
      "INFO:tensorflow:loss = 140.784, step = 1001 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 712.229\n",
      "INFO:tensorflow:loss = 189.001, step = 1101 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 675.409\n",
      "INFO:tensorflow:loss = 134.499, step = 1201 (0.149 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1280 into /tmp/tmp06v_ijxe/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 104.82.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x71fb0455f748>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "nn.train(input_fn=train_input_fn,steps=40*32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Score accuracy\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_test},\n",
    "    y=y_test,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2017-12-05-21:41:01\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp06v_ijxe/model.ckpt-1280\n",
      "INFO:tensorflow:Finished evaluation at 2017-12-05-21:41:01\n",
      "INFO:tensorflow:Saving dict for global step 1280: global_step = 1280, loss = 147.715, rmse = 12.0603\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "Loss: 147.715\n",
      "Root Mean Squared Error: 12.0603\n"
     ]
    }
   ],
   "source": [
    "ev = nn.evaluate(input_fn=test_input_fn)\n",
    "print(\"Loss: %s\" % ev[\"loss\"])\n",
    "print(\"Root Mean Squared Error: %s\" % ev[\"rmse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
