{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import argparse\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 64\n",
      "epochs: 1\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1\n",
    "batch_size = 64\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print('batch size: {}'.format(batch_size))\n",
    "print('epochs: {}'.format(n_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class z24Dataset(Dataset):\n",
    "    def __init__(self, mode='training', window_size=100, normalize=True):\n",
    "        self.window_size = window_size\n",
    "        self.slices_per_file = 65536 // self.window_size\n",
    "        self.normalize = normalize\n",
    "        \n",
    "        if mode == 'training':\n",
    "            self.index_file = np.loadtxt('../tools/training_set_index.txt',dtype=str)\n",
    "        elif mode == 'testing' :\n",
    "            self.index_file = np.loadtxt('../tools/test_set_index.txt',dtype=str)\n",
    "        elif mode == 'validating':\n",
    "            self.index_file = np.loadtxt('../tools/validation_set_index.txt',dtype=str)\n",
    "        \n",
    "        self.name_index_dict = dict(zip(range(len(self.index_file)),list(self.index_file)))\n",
    "        \n",
    "        self.env_mean = np.load('../tools/env_mean.npy')\n",
    "        self.env_std = np.load('../tools/env_std.npy')\n",
    "        self.vibration_mean = np.load('../tools/vibration_mean.npy')\n",
    "        self.vibration_std = np.load('../tools/vibration_std.npy')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index_file) * self.slices_per_file\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        index_to_read = index // self.slices_per_file\n",
    "        file_to_read = self.name_index_dict[index_to_read]\n",
    "        index_in_dataframe = (index - index_to_read*self.slices_per_file) * self.window_size\n",
    "        \n",
    "        file_path_vib = '../data/z24_clean/'+file_to_read+'_vibrations.npy'\n",
    "        file_path_env = '../data/z24_clean/'+file_to_read+'_env.npy'\n",
    "        \n",
    "        memmap_vib = np.memmap(file_path_vib, dtype=np.float64, mode='r', shape=(65536, 7))\n",
    "        memmap_env = np.memmap(file_path_env, dtype=np.float64, mode='r', shape=(53,))\n",
    "\n",
    "        X_environmental = np.array(memmap_env[:])\n",
    "        X_vibration_window = np.array(memmap_vib[index_in_dataframe:index_in_dataframe+self.window_size,:])\n",
    "\n",
    "        if self.normalize:\n",
    "            X_vibration_window = (X_vibration_window - self.vibration_mean) / self.vibration_std\n",
    "            X_environmental = (X_environmental - self.env_mean) / self.env_std\n",
    "        \n",
    "        X_vib_and_env = np.append(X_vibration_window.flatten(),X_environmental)\n",
    "       \n",
    "        return X_vib_and_env, X_vibration_window.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, z_size, output_size, dropout_p):\n",
    "        super(Model, self).__init__()\n",
    "        self.dropout_p = dropout_p\n",
    "\n",
    "        self.h1 = nn.Linear(input_size, hidden_size)\n",
    "        self.z  = nn.Linear(hidden_size, z_size)\n",
    "        self.h2 = nn.Linear(z_size, hidden_size)\n",
    "        self.h3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.dropout(x, p=self.dropout_p, training=True)\n",
    "        x = F.leaky_relu(self.h1(x))\n",
    "        x = F.dropout(x, p=self.dropout_p, training=True)\n",
    "        x = F.leaky_relu(self.z(x))\n",
    "        x = F.dropout(x, p=self.dropout_p, training=True)\n",
    "        x = F.leaky_relu(self.h2(x))\n",
    "        x = F.dropout(x, p=self.dropout_p, training=True)\n",
    "        x = self.h3(x)\n",
    "        return x\n",
    "        \n",
    "class Initializer:\n",
    "    # to apply xavier_uniform:\n",
    "    #Initializer.initialize(model=net, initialization=init.xavier_uniform_, gain=init.calculate_gain('relu'))\n",
    "    # or maybe normal distribution:\n",
    "    #Initializer.initialize(model=net, initialization=init.normal_, mean=0, std=0.2)\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def initialize(model, initialization, **kwargs):\n",
    "        def weights_init(m):\n",
    "            if isinstance(m, nn.Linear):\n",
    "                initialization(m.weight.data, **kwargs)\n",
    "                try:\n",
    "                    initialization(m.bias.data)\n",
    "                except:\n",
    "                    pass\n",
    "        model.apply(weights_init)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "dropout_p = 0.1\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-6\n",
    "weight_init = init.xavier_normal_\n",
    "hidden_size = 500\n",
    "z_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model\n",
    "model = Model(input_size=7*100+53,\n",
    "              hidden_size=hidden_size,\n",
    "              z_size=z_size,\n",
    "              output_size=7*100,\n",
    "              dropout_p=dropout_p).to(device)\n",
    "\n",
    "Initializer.initialize(model=model, initialization=weight_init)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                            lr=learning_rate,\n",
    "                            betas=(0.9, 0.99),\n",
    "                            eps=1e-08,\n",
    "                            weight_decay=0,\n",
    "                            amsgrad=True)\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "828300"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datasets\n",
    "training_dataset = z24Dataset(mode='training', window_size=100, normalize=True)\n",
    "training_dataloader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "validating_dataset = z24Dataset(mode='validating', window_size=100, normalize=True)\n",
    "validating_dataloader = DataLoader(validating_dataset, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_full = torch.nn.MSELoss(reduce=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsteinar/miniconda3/lib/python3.6/site-packages/torch/serialization.py:333: UserWarning: Couldn't retrieve source code for container of type Model. It won't be checked for correctness upon loading.\n",
      "  \"type \" + container_type.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(f='../results/trained_autoencoder_memmap.pt',map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchloss_train = []\n",
    "for X_train, Y_train in validating_dataloader:\n",
    "    X_train_tensor = X_train.float().to(device)\n",
    "    Y_train_tensor = Y_train.float().to(device)\n",
    "    \n",
    "    batch_size, output_size = Y_train.shape\n",
    "    N = 100\n",
    "    N_predictions = torch.zeros([N, batch_size, output_size])\n",
    "    \n",
    "    for i in range(N):\n",
    "        N_predictions[i,:,:] = model(X_train_tensor)\n",
    "    \n",
    "    prediction_mean = torch.mean(N_predictions, dim=0)\n",
    "    prediction_std = torch.std(N_predictions, dim=0)\n",
    "\n",
    "    trainloss_full = loss_full(predicted_Y, Y_train_tensor)\n",
    "    \n",
    "    lower_y = predicted_Y - 2*prediction_std\n",
    "    upper_y = predicted_Y + 2*prediction_std\n",
    "    within_lower = Y_train_tensor > lower_y\n",
    "    within_upper = Y_train_tensor < upper_y\n",
    "    within_range = within_lower & within_upper\n",
    "    \n",
    "    trainloss_full[within_range] = 0\n",
    "    \n",
    "    uncertainty_loss = torch.sum(trainloss_full)/ torch.numel(trainloss_full)\n",
    "\n",
    "    batchloss_train.append(uncertainty_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.616243839263916"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6163)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = torch.sum(trainloss_full)/ torch.numel(trainloss_full)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = X_train.shape[0]\n",
    "\n",
    "lower_y = predicted_Y - 1\n",
    "upper_y = predicted_Y + 1\n",
    "within_lower = Y_train_tensor > lower_y\n",
    "within_upper = Y_train_tensor < upper_y\n",
    "within_range = within_lower & within_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  1,  1,  ...,  1,  1,  1],\n",
       "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "        ...,\n",
       "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
       "        [ 1,  1,  1,  ...,  1,  1,  1]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "within_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  1,  ...,  1,  1,  1],\n",
       "        [ 0,  1,  1,  ...,  1,  1,  1],\n",
       "        [ 0,  1,  1,  ...,  1,  1,  1],\n",
       "        ...,\n",
       "        [ 0,  1,  1,  ...,  1,  1,  1],\n",
       "        [ 0,  1,  1,  ...,  1,  1,  1],\n",
       "        [ 0,  1,  1,  ...,  1,  1,  1]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "within_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  1,  ...,  1,  1,  1],\n",
       "        [ 0,  1,  1,  ...,  1,  1,  1],\n",
       "        [ 0,  1,  1,  ...,  1,  1,  1],\n",
       "        ...,\n",
       "        [ 0,  1,  1,  ...,  1,  1,  1],\n",
       "        [ 0,  1,  1,  ...,  1,  1,  1],\n",
       "        [ 0,  1,  1,  ...,  1,  1,  1]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "within_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(20778)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "within_range.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "lol = trainloss_full.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "lol[within_range] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(38925.3906)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(lol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(41861.0156)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(trainloss_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1.5029109, dtype=float32)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncertainty_loss = torch.sum(lol)/ torch.numel(lol)\n",
    "uncertainty_loss.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25900"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloss_full.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.1033847e+00, -7.7909879e-02,  9.0226103e-03, ...,\n",
       "         4.1447887e-03,  7.7459201e-02, -3.4782525e-02],\n",
       "       [ 2.6750982e+00,  1.6679198e-01, -7.4148878e-02, ...,\n",
       "        -2.8725275e-01, -3.7195751e-01,  3.8336131e-01],\n",
       "       [ 2.1140544e+00, -2.1987635e-01, -2.2084813e-03, ...,\n",
       "         2.2950126e-02, -1.7995991e-01, -1.3363613e-01],\n",
       "       ...,\n",
       "       [ 2.2500920e+00, -1.9684860e-01, -3.9239279e-03, ...,\n",
       "         3.9925534e-02,  5.2312654e-02, -1.5650688e-01],\n",
       "       [ 2.0687084e+00, -7.5941764e-02,  9.3081184e-03, ...,\n",
       "         5.2884631e-03,  8.5518353e-02, -4.7565304e-02],\n",
       "       [ 2.4679298e+00,  4.3799764e-01, -2.3930125e-01, ...,\n",
       "        -3.3142719e-01, -3.4920231e-01,  5.4056108e-01]], dtype=float32)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_tensor.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 37, 700])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = torch.mean(N_predictions, dim=0)\n",
    "std = torch.std(N_predictions, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty_loss = torch.sum(trainloss_full)/ torch.numel(trainloss_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.298634648323059"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncertainty_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2986)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncertainty_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
